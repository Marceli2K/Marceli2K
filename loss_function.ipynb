{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "loss_function.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNaO519ND01O/Soi4/DuSm5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zaratrusztra/Zaratrusztra/blob/master/loss_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWD9CUFeOaul",
        "colab_type": "text"
      },
      "source": [
        "##Acurracy\n",
        "### $Accuracy = \\frac {correct \\ predictions}{total \\ predictions} * 100$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRoHcwmEOuks",
        "colab_type": "code",
        "outputId": "5525d611-29e6-4d5e-e6a7-9dc928bf1ef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "y_true = np.array([1,0,1,1,0,1])\n",
        "y_pred = np.array([0,0,1,1,0,1])\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  correct = 0\n",
        "  for i in range(len(y_true)):\n",
        "    if y_true[i]==y_pred[i]:\n",
        "      correct=correct + 1\n",
        "  return (correct / len(y_pred))*100\n",
        "\n",
        "accuracy(y_true,y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83.33333333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuRHC1Xb5pFB",
        "colab_type": "text"
      },
      "source": [
        "## **Entropia rozkładu prawdopodobieństwa**\n",
        "### $Entropy = - \\sum _{i}p_{i} * log(p_{i})$\n",
        "\n",
        "*Gdzie $p_{i}$ to prawdopodobieństwo zajścia i-tego zdarzenia. Entropia charaktryzuje możliwość oddawania informacji przez źródło. Inaczej jest to miara nieokreśloności/ niepewności. Średnie zdziwienie/wartość oczekiwania zdziwienia.* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Vu8_RQxQnTp",
        "colab_type": "code",
        "outputId": "80c0692d-7a59-4c43-df70-d5cbc7b84475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "def entropy(labels, base=None):\n",
        "  from math import log, e\n",
        "  n_labels = len(labels)\n",
        "  if n_labels <= 1:\n",
        "    return 0\n",
        "  \n",
        "  value, counts = np.unique(labels, return_counts = True)\n",
        "  probs = counts / n_labels\n",
        "  n_classes = np.count_nonzero(probs)\n",
        "\n",
        "  if n_classes <= 1:\n",
        "    return 0\n",
        "  ent = 0.\n",
        "\n",
        "  base = e if base is None else base\n",
        "  for i in probs:\n",
        "    ent -= i * log(i, base)\n",
        "  return ent\n",
        "\n",
        "labels=[1,3,5,2,3,5,3,2,1,3,4,5]\n",
        "entropy(labels)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5171063970610277"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvNeozPIV6bY",
        "colab_type": "text"
      },
      "source": [
        "## Binary Crossentropy - Binarna Entropia Kryżowa\n",
        "$BinaryCrossEntropy = -y_{true} * log(y_{pred}) - (1 - y_{true}) * log(1 - y_{pred})$\n",
        "\n",
        "###Funkcja straty używana w problemach klasyfikacji binarnej."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTM3xQJhWab7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true = np.array([1,0,1,1,0,1,0])\n",
        "y_pred = np.array([0,0,1,1,0,1,1])\n",
        "binary_crossentropy(y_true,y_pred):\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}